{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4985a208",
   "metadata": {},
   "source": [
    "#### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6330570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "CLASSIFICATIONS = {\n",
    "    0: 'none',\n",
    "    1: 'remove_duplicate_values',\n",
    "    2: 'fill_missing_values',\n",
    "    3: 'perform_dimensionality_reduction',\n",
    "    4: 'perform_correlation_analysis',\n",
    "}\n",
    "\n",
    "system_prompts = {f.stem: f.read_text() for f in Path(\"system_prompt\").glob(\"*.txt\")}\n",
    "system_prompt_classification = system_prompts['classification'].format(functions_dict=str(CLASSIFICATIONS))\n",
    "\n",
    "user_prompts = [f.read_text() for f in Path(\"user_prompt\").glob(\"*.txt\")]\n",
    "structured_outputs = {f.stem: json.load(f.open('r')) for f in Path(\"structured_output\").glob(\"*.json\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b2f57b",
   "metadata": {},
   "source": [
    "#### Main System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac8850a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def postprocess_classification_respond(respond):\n",
    "    match = re.search(r'\\d+', respond)\n",
    "    if match:\n",
    "        res = int(match.group(0))\n",
    "        if res < len(CLASSIFICATIONS) and res > 0:\n",
    "            return res\n",
    "    return 0\n",
    "\n",
    "def perform_classification(client, user_request):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt_classification,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_request,\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"solar-pro\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return postprocess_classification_respond(response.choices[0].message.content)\n",
    "\n",
    "def perform_function_mapping(client, user_request, system_prompt, structured_output):\n",
    "    messages = [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': system_prompt\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': user_request\n",
    "            }\n",
    "        ]\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"solar-pro\",\n",
    "            messages=messages,\n",
    "            response_format=structured_output\n",
    "        )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def process_user_request(client, user_request):\n",
    "    '''\n",
    "    Outpupt: function_name (string), function_parameters (JSON), model_respond (string)\n",
    "    Return the JSON string with the information of the function that the user want to call together the respond of the system.\n",
    "    '''\n",
    "    try:\n",
    "        classification = perform_classification(client, user_request)\n",
    "        function_name = CLASSIFICATIONS[classification]\n",
    "        function_parameters = {}\n",
    "        \n",
    "        if classification != 0:\n",
    "            function_parameters = perform_function_mapping(\n",
    "                client, user_request, \n",
    "                system_prompt = system_prompts[CLASSIFICATIONS[classification]], \n",
    "                structured_output = structured_outputs[CLASSIFICATIONS[classification]])\n",
    "            function_parameters = json.loads(function_parameters)\n",
    "        return True, function_name, function_parameters\n",
    "    except Exception as e:\n",
    "        return False, e, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b29d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def check_cols_in_dataframe(df: pd.DataFrame, cols):\n",
    "    # Edge Cases\n",
    "    if cols is None or cols == []:\n",
    "        return True\n",
    "    df_columns = df.columns\n",
    "    \n",
    "    for col in cols:\n",
    "        if col not in df_columns:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def convert_subset_to_message(subset):\n",
    "    return subset if subset not in [None, []] else 'all'\n",
    "\n",
    "'''\n",
    "The funcitons below return success (bool), message (str), processed_data (pandas.DataFrame), image\n",
    "'''\n",
    "def remove_duplicate_values(df: pd.DataFrame, subset, keep):\n",
    "    if keep not in ['first', 'last', False]:\n",
    "        return False, f'Keep is not recognized: {keep}', None, None\n",
    "    \n",
    "    if check_cols_in_dataframe(df,subset):\n",
    "        try:\n",
    "            return_message = f'Here is your data with duplicate values remove in subset: {convert_subset_to_message(subset)}, keep: {keep}'\n",
    "            return True, return_message, df.drop_duplicates(subset=subset, keep=keep), None\n",
    "        except Exception as e:\n",
    "            return False, e, None, None\n",
    "    else:\n",
    "        return False, f'Columns not in the DataFrame: {subset}', None, None\n",
    "    \n",
    "def fill_missing_values(df: pd.DataFrame, subset, metric):\n",
    "    if metric not in ['mean', 'median', 'mode']:\n",
    "        return False, f'Metric is not recognized: {metric}', None, None\n",
    "    \n",
    "    if check_cols_in_dataframe(df, subset):\n",
    "        try:\n",
    "            return_message = f'Here is your data with missing values remove in subset: {convert_subset_to_message(subset)}, metric: {metric}'\n",
    "            df_result = df.copy()\n",
    "            \n",
    "            for col in subset:\n",
    "                if metric == 'mean':\n",
    "                    fill_value = round(df_result[col].mean(), 3)\n",
    "                elif metric == 'median':\n",
    "                    fill_value = round(df_result[col].median(), 3)\n",
    "                elif metric == 'mode':\n",
    "                    fill_value = df_result[col].mode()\n",
    "                df_result[col].fillna(fill_value, inplace=True)\n",
    "            return True, return_message, df_result, None\n",
    "        except Exception as e:\n",
    "            return False, e, None, None\n",
    "    else:\n",
    "        return False, f'Columns not in the DataFrame: {subset}', None, None\n",
    "    \n",
    "    \n",
    "def perform_correlation_analysis(df: pd.DataFrame, subset):\n",
    "    if check_cols_in_dataframe(df, subset):\n",
    "        try:\n",
    "            corr = df[subset].corr()\n",
    "            plt.figure()\n",
    "            sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "            plt.title('Correlation Heatmap')\n",
    "            buf = io.BytesIO()\n",
    "            plt.savefig(buf, format='png')\n",
    "            plt.close()\n",
    "            buf.seek(0)\n",
    "            img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
    "            return True, f'Here is the correlation analysis in subset: {convert_subset_to_message(subset)}', corr, img_base64\n",
    "        except Exception as e:\n",
    "            return False, e, None, None\n",
    "    else:\n",
    "        return False, f'Columns not in the DataFrame: {subset}', None, None\n",
    "    \n",
    "def perform_dimensionality_reduction(df: pd.DataFrame, features, target):\n",
    "    subset = features.append(target)\n",
    "    \n",
    "    if check_cols_in_dataframe(df, subset):\n",
    "        try:\n",
    "            return_message = f'Here is the pca result of features: {features}, target: {target}'\n",
    "            # PCA\n",
    "            X = df[features]\n",
    "            pca = PCA(n_components=2)\n",
    "            X_pca = pca.fit_transform(X)\n",
    "            pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'], index=df.index)\n",
    "            y = df[target]\n",
    "            \n",
    "            # Plot\n",
    "            plt.figure(figsize=(8,6))\n",
    "            sns.scatterplot(x='PC1', y='PC2', hue=y, palette='viridis', data=pca_df.join(y))\n",
    "            plt.title('PCA Scatter Plot (PC1 vs PC2)')\n",
    "            plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.2f}% variance)')\n",
    "            plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.2f}% variance)')\n",
    "            plt.legend(title=target)\n",
    "            \n",
    "            buf = io.BytesIO()\n",
    "            plt.savefig(buf, format='png')\n",
    "            plt.close()\n",
    "            buf.seek(0)\n",
    "            img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
    "            \n",
    "            pca_params = {\n",
    "                'explained_variance_ratio': pca.explained_variance_ratio_.tolist(),\n",
    "                'components': pca.components_.tolist()\n",
    "            }\n",
    "            return True, return_message, [pca_df, y, pca_params], img_base64 \n",
    "        except Exception as e:\n",
    "            return False, e, None, None\n",
    "    else:\n",
    "        return False, f'Columns not in the DataFrame: {subset}', None, None\n",
    "        \n",
    "def map_json_to_function(df: pd.DataFrame, function_name, function_parameters):\n",
    "    if function_name == 'remove_duplicate_values':\n",
    "        return remove_duplicate_values(df, subset=function_parameters['subset'], keep=function_parameters['keep'])\n",
    "    elif function_name == 'fill_missing_values':\n",
    "        return fill_missing_values(df, subset=function_parameters['subset'], metric=function_parameters['metric'])\n",
    "    elif function_name == 'perform_correlation_analysis':\n",
    "        return perform_correlation_analysis(df, subset=function_parameters['subset'])\n",
    "    elif function_name == 'perform_dimensionality_reduction':\n",
    "        return perform_dimensionality_reduction(df, features=function_parameters['features'], target=function_parameters['target'])\n",
    "    else:\n",
    "        return False, f'No function recognized.', None, None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c9c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"../../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../../data/test.csv\")\n",
    "modified_train_df = pd.read_csv(\"../../data/modified_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a30f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_prompt: Please remove duplication values in columns temp, atemp, and humidity; don't keep any value.\n",
      "function_name: remove_duplicate_values\n",
      "function_parameters: {'keep': 'last', 'subset': ['temp', 'atemp', 'humidity']}\n",
      "Here is your data with duplicate values remove in subset: ['temp', 'atemp', 'humidity'], keep: last\n",
      "\n",
      "user_prompt: Fill the NULL values in column atemp using the column's mode.\n",
      "function_name: fill_missing_values\n",
      "function_parameters: {'metric': 'mode', 'subset': ['atemp']}\n",
      "Here is your data with missing values remove in subset: ['atemp'], metric: mode\n",
      "\n",
      "user_prompt: I want you to perform PCA on columns temp, atemp, and humidity. The target column is holiday.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_425308\\2597055262.py:54: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_result[col].fillna(fill_value, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_name: perform_dimensionality_reduction\n",
      "function_parameters: {'features': ['temp', 'atemp', 'humidity'], 'target': 'holiday'}\n",
      "Here is the pca result of features: ['temp', 'atemp', 'humidity', 'holiday'], target: holiday\n",
      "\n",
      "user_prompt: I want you to output the correlation map of columns atemp, temp, and humidity.\n",
      "function_name: 'perform_correlation_analysis'\n",
      "function_parameters: {}\n",
      "user_prompt: After spending most of his life uniting the Mongol tribes, he launched a series of military campaigns, conquering large parts of China and Central Asia.\n",
      "function_name: none\n",
      "function_parameters: {}\n",
      "No function recognized.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import toml\n",
    "\n",
    "parsed_toml = toml.load('../../../secrets.toml')\n",
    "\n",
    "client = OpenAI(\n",
    "\tapi_key=parsed_toml['upstage_api_key'], \n",
    " \tbase_url=\"https://api.upstage.ai/v1\"\n",
    ")\n",
    "\n",
    "# User Prompt 1: NA Data\n",
    "user_prompt = user_prompts[0]\n",
    "print(f\"user_prompt: {user_prompt}\")\n",
    "success_function_info, function_name, function_parameters = process_user_request(client, user_request=user_prompt)\n",
    "print(f\"function_name: {function_name}\")\n",
    "print(f\"function_parameters: {function_parameters}\")\n",
    "if success_function_info:\n",
    "        success_request, message, data_1, graph_1 = map_json_to_function(modified_train_df, function_name, function_parameters)\n",
    "        print(message)\n",
    "        print()\n",
    "\n",
    "# User Prompt 2: NA Data\n",
    "user_prompt = user_prompts[1]\n",
    "print(f\"user_prompt: {user_prompt}\")\n",
    "success_function_info, function_name, function_parameters = process_user_request(client, user_request=user_prompt)\n",
    "print(f\"function_name: {function_name}\")\n",
    "print(f\"function_parameters: {function_parameters}\")\n",
    "if success_function_info:\n",
    "        success_request, message, data_2, graph_2 = map_json_to_function(modified_train_df, function_name, function_parameters)\n",
    "        print(message)\n",
    "        print()\n",
    "\n",
    "# User Prompt 3: Non NA Data\n",
    "user_prompt = user_prompts[2]\n",
    "print(f\"user_prompt: {user_prompt}\")\n",
    "success_function_info, function_name, function_parameters = process_user_request(client, user_request=user_prompt)\n",
    "print(f\"function_name: {function_name}\")\n",
    "print(f\"function_parameters: {function_parameters}\")\n",
    "if success_function_info:\n",
    "        success_request, message, data_3, graph_3 = map_json_to_function(train_df, function_name, function_parameters)\n",
    "        print(message)\n",
    "        print()\n",
    "\n",
    "# User Prompt 4: Non NA Data\n",
    "user_prompt = user_prompts[3]\n",
    "print(f\"user_prompt: {user_prompt}\")\n",
    "success_function_info, function_name, function_parameters = process_user_request(client, user_request=user_prompt)\n",
    "print(f\"function_name: {function_name}\")\n",
    "print(f\"function_parameters: {function_parameters}\")\n",
    "if success_function_info:\n",
    "        success_request, message, data_4, graph_4 = map_json_to_function(train_df, function_name, function_parameters)\n",
    "        print(message)\n",
    "        print()\n",
    "\n",
    "# User Prompt 5: \n",
    "user_prompt = user_prompts[4]\n",
    "print(f\"user_prompt: {user_prompt}\")\n",
    "success_function_info, function_name, function_parameters = process_user_request(client, user_request=user_prompt)\n",
    "print(f\"function_name: {function_name}\")\n",
    "print(f\"function_parameters: {function_parameters}\")\n",
    "if success_function_info:\n",
    "        success_request, message, data_5, graph_5 = map_json_to_function(train_df, function_name, function_parameters)\n",
    "        print(message)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41792537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_prompt: I want you to output the heat map of columns atemp, temp, and humidity.\n",
      "function_name: perform_correlation_analysis\n",
      "function_parameters: {'subset': ['atemp', 'temp', 'humidity']}\n",
      "Here is the correlation analysis in subset: ['atemp', 'temp', 'humidity']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# User Prompt 4: Non NA Data\n",
    "user_prompt = user_prompts[3]\n",
    "print(f\"user_prompt: {user_prompt}\")\n",
    "success_function_info, function_name, function_parameters = process_user_request(client, user_request=user_prompt)\n",
    "print(f\"function_name: {function_name}\")\n",
    "print(f\"function_parameters: {function_parameters}\")\n",
    "if success_function_info:\n",
    "        success_request, message, data_4, graph_4 = map_json_to_function(train_df, function_name, function_parameters)\n",
    "        print(message)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048e5211",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97eef8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: bool)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplications = data_1.duplicated()\n",
    "duplications[duplications == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8fcd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        14.395\n",
       "1        13.635\n",
       "2        13.635\n",
       "3        14.395\n",
       "4        14.395\n",
       "          ...  \n",
       "11425    28.790\n",
       "11426    25.760\n",
       "11427    22.725\n",
       "11428    12.880\n",
       "11429    25.760\n",
       "Name: atemp, Length: 11430, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2['atemp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f87447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[             PC1        PC2\n",
       " 0      19.781460 -12.888486\n",
       " 1      18.838205 -14.050746\n",
       " 2      18.838205 -14.050746\n",
       " 3      13.788877 -13.184217\n",
       " 4      13.788877 -13.184217\n",
       " ...          ...        ...\n",
       " 10881 -11.568141  -6.640351\n",
       " 10882  -4.472997  -8.520107\n",
       " 10883  -0.398288  -9.991826\n",
       " 10884  -0.446737  -8.876341\n",
       " 10885   4.602591  -9.742871\n",
       " \n",
       " [10886 rows x 2 columns],\n",
       " 0        0\n",
       " 1        0\n",
       " 2        0\n",
       " 3        0\n",
       " 4        0\n",
       "         ..\n",
       " 10881    0\n",
       " 10882    0\n",
       " 10883    0\n",
       " 10884    0\n",
       " 10885    0\n",
       " Name: holiday, Length: 10886, dtype: int64,\n",
       " {'explained_variance_ratio': [0.7376217211210322, 0.2603843045546407],\n",
       "  'components': [[-0.03805444855608231,\n",
       "    -0.031979085849069694,\n",
       "    0.9987638343051585,\n",
       "    1.724551398659321e-05],\n",
       "   [0.674864570261991,\n",
       "    0.736293726279616,\n",
       "    0.04928852878252111,\n",
       "    -3.710566027481271e-05]]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bbac05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(io.BytesIO(base64.decodebytes(bytes(graph_3, \"utf-8\"))))\n",
    "if img.mode in (\"RGBA\", \"P\"):\n",
    "    img = img.convert(\"RGB\")\n",
    "img.save('pca.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e5eaedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atemp</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atemp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984948</td>\n",
       "      <td>-0.043536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>0.984948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.064949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>-0.043536</td>\n",
       "      <td>-0.064949</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             atemp      temp  humidity\n",
       "atemp     1.000000  0.984948 -0.043536\n",
       "temp      0.984948  1.000000 -0.064949\n",
       "humidity -0.043536 -0.064949  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "209fba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(io.BytesIO(base64.decodebytes(bytes(graph_4, \"utf-8\"))))\n",
    "if img.mode in (\"RGBA\", \"P\"):\n",
    "    img = img.convert(\"RGB\")\n",
    "img.save('correlation-analysis.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7777f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
